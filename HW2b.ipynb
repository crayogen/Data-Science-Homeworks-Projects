{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2b - Feature Extraction and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the homework we'll be looking at the same dataset except in a completely different light. We'll move beyond simply analysing the data and will instead move towards trying to make some inferences regarding the data - predictions on when the dam's target value of (the minimum estimate) 1.5 Trillion rupees will be reached. Use the same set-up as part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>ADC 0117</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>SARFARAZ 0117</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>HAMNA ZEESHAN 0117</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>ADC 0117</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>NOMAN 0117</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Bank                Name  Amount       Date\n",
       "0  AL BARAKA BANK (PAKISTAN) LTD            ADC 0117    25.0 2018-09-10\n",
       "1  AL BARAKA BANK (PAKISTAN) LTD       SARFARAZ 0117   100.0 2018-09-10\n",
       "2  AL BARAKA BANK (PAKISTAN) LTD  HAMNA ZEESHAN 0117   100.0 2018-09-10\n",
       "3  AL BARAKA BANK (PAKISTAN) LTD            ADC 0117   200.0 2018-09-10\n",
       "4  AL BARAKA BANK (PAKISTAN) LTD          NOMAN 0117   200.0 2018-09-10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "data = pd.read_pickle('./individual_contributions.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be running a regression analysis on this data since the target variable, the funds collected, is a continuous variable. Before we are able to run any sort of regression we need to decide what features we should be using for our regression. Moreover, since we are running a regression it is important to also figure out what exactly our target variable should be. Should it be the **cumulative sum** of the amount collected **till** each day, or should it simply be the amount collected **on** each day? Whatever you decide, write code below to get that target variable. \n",
    "\n",
    "Hint: Using groupby on \"Date\" would be a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to calculate the target variable\n",
    "\n",
    "# I can't train on the Year feature vector, because all the data collected is from the same year.\n",
    "\n",
    "# Initially I ran my model with cummulative sum of amount collected till each day\n",
    "# but I did not go with that in the end, because predicting the cummulative amount \n",
    "# without having my model train on the 'Year' feature doesn't not work.\n",
    "# Months, Days, and Dates are all recurrent so the model keeps predicting the same\n",
    "# cummulative amounts each year\n",
    "\n",
    "# So I ended up predicting the daily contribution\n",
    "\n",
    "grouped_data = data.groupby('Date').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Feature Extraction (20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You currently have 3 columns, other than the target variable (Amount), Bank, Name and Date. Which do you think should be used as the independent variable in running the regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible variable we could use is the Date variable, but it can not be used directly since it is a 'Datetime' object. Read up more on Linear Regression on the [sklearn Documentation page](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) to know about what sort of independent variables must be sent to it.\n",
    "\n",
    "There are many different ways you can extract the right features from just the datetime column. Some useful in-built functions include the sklearn library's [LabelEncoder](http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder), the [OneHotEncoder](http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) and the [OrdinalEncoder](http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder).\n",
    "\n",
    "You need to think deeply about what sort of variables can be extracted from simply \"Date\", and how they would be useful in trying to figure out how many funds are being collected on any given day. One good way to go about it would be to try out the regression on many different features and see which one is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06803593218120563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Day_int</th>\n",
       "      <th>Date_int</th>\n",
       "      <th>Month_int</th>\n",
       "      <th>Year_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>2.402300e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>1.346261e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>5.374641e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>2.483002e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2.917482e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>2.223476e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>3.108752e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>4.613922e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>3.931781e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>3.273330e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>1.745405e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>2.515149e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>3.165851e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>3.659775e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>1.124021e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>5.921273e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>5.691998e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>4.140543e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>2.118541e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>1.553184e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>4.248558e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>2.757162e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>6.332110e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>8.696471e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>2.715461e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>2.180158e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>8.027582e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>1.861185e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>1.504234e+08</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>6.628996e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>7.917167e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>7.626580e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2.476699e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>6.025480e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>2.681529e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>3.572914e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>9.933391e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>3.739117e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>2.962764e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>4.893712e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>5.233332e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>9.188571e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>9.061704e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>1.702792e+08</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>9.311208e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>8.558529e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>1.697207e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>1.244504e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>1.069135e+08</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>1.043583e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>1.634917e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>9.944445e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>5.181083e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>3.349218e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>9.945763e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2.562500e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>5.352290e+07</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>9.240164e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>3.780949e+07</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Amount  Day_int  Date_int  Month_int  Year_int\n",
       "0  2018-07-06  2.402300e+06        4         6          7      2018\n",
       "1  2018-07-09  1.346261e+06        0         9          7      2018\n",
       "2  2018-07-10  5.374641e+06        1        10          7      2018\n",
       "3  2018-07-11  2.483002e+07        2        11          7      2018\n",
       "4  2018-07-12  2.917482e+07        3        12          7      2018\n",
       "5  2018-07-13  2.223476e+07        4        13          7      2018\n",
       "6  2018-07-16  3.108752e+07        0        16          7      2018\n",
       "7  2018-07-17  4.613922e+07        1        17          7      2018\n",
       "8  2018-07-18  3.931781e+07        2        18          7      2018\n",
       "9  2018-07-19  3.273330e+07        3        19          7      2018\n",
       "10 2018-07-20  1.745405e+07        4        20          7      2018\n",
       "11 2018-07-23  2.515149e+07        0        23          7      2018\n",
       "12 2018-07-24  3.165851e+07        1        24          7      2018\n",
       "13 2018-07-26  3.659775e+07        3        26          7      2018\n",
       "14 2018-07-27  1.124021e+07        4        27          7      2018\n",
       "15 2018-07-30  5.921273e+07        0        30          7      2018\n",
       "16 2018-07-31  5.691998e+07        1        31          7      2018\n",
       "17 2018-08-01  4.140543e+07        2         1          8      2018\n",
       "18 2018-08-02  2.118541e+07        3         2          8      2018\n",
       "19 2018-08-03  1.553184e+07        4         3          8      2018\n",
       "20 2018-08-06  4.248558e+07        0         6          8      2018\n",
       "21 2018-08-07  2.757162e+07        1         7          8      2018\n",
       "22 2018-08-08  6.332110e+07        2         8          8      2018\n",
       "23 2018-08-09  8.696471e+07        3         9          8      2018\n",
       "24 2018-08-10  2.715461e+07        4        10          8      2018\n",
       "25 2018-08-13  2.180158e+07        0        13          8      2018\n",
       "26 2018-08-15  8.027582e+07        2        15          8      2018\n",
       "27 2018-08-16  1.861185e+07        3        16          8      2018\n",
       "28 2018-08-17  1.504234e+08        4        17          8      2018\n",
       "29 2018-08-20  6.628996e+07        0        20          8      2018\n",
       "30 2018-08-24  7.917167e+07        4        24          8      2018\n",
       "31 2018-08-27  7.626580e+07        0        27          8      2018\n",
       "32 2018-08-28  2.476699e+08        1        28          8      2018\n",
       "33 2018-08-29  6.025480e+07        2        29          8      2018\n",
       "34 2018-08-30  2.681529e+07        3        30          8      2018\n",
       "35 2018-08-31  3.572914e+07        4        31          8      2018\n",
       "36 2018-09-03  9.933391e+07        0         3          9      2018\n",
       "37 2018-09-04  3.739117e+07        1         4          9      2018\n",
       "38 2018-09-05  2.962764e+07        2         5          9      2018\n",
       "39 2018-09-06  4.893712e+07        3         6          9      2018\n",
       "40 2018-09-07  5.233332e+07        4         7          9      2018\n",
       "41 2018-09-10  9.188571e+07        0        10          9      2018\n",
       "42 2018-09-11  9.061704e+08        1        11          9      2018\n",
       "43 2018-09-12  1.702792e+08        2        12          9      2018\n",
       "44 2018-09-13  9.311208e+07        3        13          9      2018\n",
       "45 2018-09-14  8.558529e+07        4        14          9      2018\n",
       "46 2018-09-17  1.697207e+08        0        17          9      2018\n",
       "47 2018-09-18  1.244504e+08        1        18          9      2018\n",
       "48 2018-09-19  1.069135e+08        2        19          9      2018\n",
       "49 2018-09-24  1.043583e+08        0        24          9      2018\n",
       "50 2018-09-25  1.634917e+08        1        25          9      2018\n",
       "51 2018-09-26  9.944445e+07        2        26          9      2018\n",
       "52 2018-09-27  5.181083e+07        3        27          9      2018\n",
       "53 2018-09-28  3.349218e+07        4        28          9      2018\n",
       "54 2018-10-01  9.945763e+07        0         1         10      2018\n",
       "55 2018-10-02  2.562500e+05        1         2         10      2018\n",
       "56 2018-10-03  5.352290e+07        2         3         10      2018\n",
       "57 2018-10-04  9.240164e+07        3         4         10      2018\n",
       "58 2018-10-05  3.780949e+07        4         5         10      2018"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the appropriate functions from sklearn #\n",
    "# Extract the right features #\n",
    "# An example of one feature that could be extracted is given below #\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# banks = data['Bank'].unique()\n",
    "# print(banks)\n",
    "\n",
    "# This finds what day of the week it is from the datetime object where 0 is Monday and 6 is Sunday\n",
    "\n",
    "def extract_features(grouped_data):\n",
    "    grouped_data['Day_int'] = grouped_data['Date'].dt.dayofweek\n",
    "    grouped_data['Date_int'] = grouped_data['Date'].dt.day\n",
    "    grouped_data['Month_int'] = grouped_data['Date'].dt.month\n",
    "    ## The year number should not provide any information because all data is from teh same year, day of year?\n",
    "    grouped_data['Year_int'] = grouped_data['Date'].dt.year\n",
    "\n",
    "extract_features(grouped_data)\n",
    "\n",
    "# months = grouped_data['Month_int'].unique()\n",
    "# print(months)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "X = grouped_data['Month_int'].to_frame()\n",
    "y = grouped_data['Amount']\n",
    "\n",
    "reg_TimeOfMonth = LinearRegression()\n",
    "reg_TimeOfMonth.fit(X,y)\n",
    "\n",
    "print(reg_TimeOfMonth.score(X, y))\n",
    "# as expected the cummulative amount has a very high correlation with month, and not so much with \n",
    "# day of week or day of month, but combined they can proivde a better model for prediction\n",
    "\n",
    "# Print the entire dataframe.head() with the extracted features at the end of this cell #\n",
    "grouped_data.head()\n",
    "grouped_data.sort_values(['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Regression and Evaluation (40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards, how exactly you structure your code is upto you, and the main goal is this: You want to choose a regression model from one of the many [linear_models](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) available on sklearn. If you're feeling adventurous you can try using [Support Vector Regression](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) as well, but unless you guys take out the time to understand how Support Vector Machines work, and why they might not be the best idea for such a dataset, it will not be a fruitful exercise.\n",
    "\n",
    "You need to learn how to evaluate your model. Every sklearn regression model has a built in function that can calculate the regression score for you (as done before), and the sklearn [Mean Squared Error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function will be used to calculate the error in your test-set and your train-set. In most cases you will use either a custom function to split the dataset into a train-test set, or use the [train-test-split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function. Another extremely useful tool is [KFold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). Research on cross-validation and why it is such an effective way to evaluate your Machine Learning models.\n",
    "\n",
    "For the purpose of this assignment, the final values will be of the regression being **trained and tested on the entire dataset**. And the following results will be looked at (print these values clearly!):\n",
    "1. Regression Score \n",
    "2. Mean Squared Error (Expect this to be really high, since the values of the data-set are also high)\n",
    "3. The Regression Line that you get from the linear-models (either from the coefficients or from the predictions) over the data-points (I will upload a sample on Piazza)\n",
    "\n",
    "**Lastly**, after you have trained your model, you need to build a mock data-set containing just the datetime objects. A good function to use is [python.date_range](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.date_range.html) that allows you to get a DateTimeIndex of whatever Date and Frequency you chose (the frequency is an extremely important parameter). You can convert that DateTimeIndex to a DataFrame and then extract the same features as you did in the previous part (making a function for feature extraction is a good idea). After that you need to print the exact **Month and Year that the 1.5 Trillion Rs target will be reached according to your regression.**\n",
    "\n",
    "**This is an iterative process and you will have to play around with the features, the model and parameters of the regression many times before you reach a good result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.2347943755240502\n",
      "regression score:  -0.39308616394638607\n",
      "regression intercept:  2.0817520167155173e-16\n",
      "regression coefficients:  [-0.10952233  0.09404737  0.20757438]\n",
      "mean squared error:  0.07621982895397654\n",
      "2028-07-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# I scaled my data so my intercepts and Mean Squared Errors are not so large\n",
    "\n",
    "X = grouped_data[['Day_int', 'Date_int', 'Month_int']]\n",
    "y = grouped_data['Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "scalery = StandardScaler().fit(y_train.values.reshape((-1,1)))\n",
    "\n",
    "X_train = scalerX.transform(X_train)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "y_train = scalery.transform(y_train.values.reshape(-1,1)).ravel()\n",
    "y_test = scalery.transform(y_test.values.reshape((-1,1))).ravel()\n",
    "\n",
    "regr = ElasticNetCV(l1_ratio = [.1, .5, .6, .7, 0.85, 0.9, .95, .99], cv = 3, n_alphas = 100, copy_X=True,\n",
    "        max_iter=1000, random_state=0, tol=0.0001)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print(\"alpha: \", regr.alpha_)\n",
    "print(\"regression score: \", regr.score(X, y))\n",
    "\n",
    "#print(\"regression score: \", regr.score(X, y))\n",
    "\n",
    "print(\"regression intercept: \", regr.intercept_) \n",
    "print(\"regression coefficients: \", regr.coef_)\n",
    "err = mean_squared_error(y_pred, y_test)\n",
    "print(\"mean squared error: \", err)\n",
    "\n",
    "# giving an arbritary range to the dates range\n",
    "dates = pd.date_range(start='2018-07-06', end='2040-07-06').to_frame()\n",
    "dates.columns = ['Date']\n",
    "extract_features(dates)\n",
    "\n",
    "target = 1.5 * (10**12)\n",
    "\n",
    "my_predictions_scaled = regr.predict(dates[['Day_int', 'Date_int', 'Month_int']])\n",
    "\n",
    "# scaling back the predictions\n",
    "my_predictions = scalery.inverse_transform(my_predictions_scaled)\n",
    "\n",
    "sum, i = 0, 0\n",
    "while sum<target:\n",
    "    sum = sum + my_predictions[i]\n",
    "    i = i+1;\n",
    "    \n",
    "print(dates.iloc[i]['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you think the limitations of your regression were? What problems did you face in not being able to get a good fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is **not large enough** to run a multiple regression properly, it is easy to **overfit** on the data.\n",
    "Morover, if data from several years, rather than several months was available then maybe a \"yearly-trend\" could also be integrated in a model, which would make sense in this context.\n",
    "\n",
    "There was no proper dealing of the **outliers**, such as the army donation, which skews our data.\n",
    "On the one hand, these outliers cannot be discarded because they constitute a large percentage of the total funds, and are needed to gain an accurate estimate of the donation pattern, and to estimate a time to reach the 1.5 trillion target of the dam project. On the other hand, the exponentially large donations drown the effect of the smaller donations.\n",
    "Maybe with more data, a seperate regression could be run on the pattern of the outlier donations, such as those from large industries, because in part(a), my calculations showed that the cummulative outlier contribution was more than the cummulative inlier contribution.\n",
    "\n",
    "Using a multiple Linear regression implies that the donation pattern wil remain constant with relation to my feature vectors, i.e month (1-12), day of month (1-30) and day of week(1-7). This is not likely to be the case in donations, because donation patterns change due to social hype and awareness etc. We don't have a feature vector to capture that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
